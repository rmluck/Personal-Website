export const projects = [
    {
        name: "Personal Website",
        type: "Web Application",
        brief: "Personal website and portfolio showcasing my projects, experience, and interests. Built with Next.js and TypeScript, featuring a modern, responsive design and interactive elements. Styled with Tailwind CSS and deployed on Vercel.",
        description: "Personal website and portfolio developed using Next.js and TypeScript to showcase my projects, experience, and interests. Features a modern, responsive design with interactive elements such as image galleries, travel maps, and blog posts. Styled with Tailwind CSS for a clean and professional look. The home page includes a background section along with featured projects, prior job experiences, educational background, and technical skills. Deployed on Vercel for optimal performance and accessibility.",
        start_date: "September 2025",
        end_date: "October 2025",
        image: "/site/home_page.png",
        skills: {
            languages: ["TypeScript"],
            frameworks: ["React", "Next.js", "Node.js", "Tailwind CSS", "Framer Motion", "Vanta.js", "Lucide", "Sharp", "Leaflet", "GeoJSON"],
            tools: ["Git", "ESLint", "PostCSS", "Sanity", "Formspree", "Cloudinary", "Vercel", "Cloudflare"],
            domains: [],
            soft_skills: [],
        },
        links: [
            {
                label: "GitHub",
                url: "https://github.com/rmluck/personal-website",
            },
            {
                label: "Live Site",
                url: "https://rohanmistry.me",
            },
        ],
        featured: false,
    },
    {
        name: "NASA Media Explorer",
        type: "Web Application",
        brief: "Full-stack search engine application that indexes and searches [NASA's media archive of images and videos](https://images.nasa.gov), providing interactive media exploration platform.",
        description: "Sophisticated full-stack search engine that transforms how users discover and explore [NASA's vast media archive](https://images.nasa.gov). The application intelligently indexes over 100,000 historical images and videos spanning from 1920 to present, implementing advanced information retrieval techniques including inverted indexing, Okapi BM25 document scoring, and natural language processing with spaCy for context-aware search capabilities.\nThe system features a custom-built Python backend leveraging FastAPI for high-performance API development, automated web crawling for data acquisition, and optimized indexing algorithms that enable sub-second search responses across the massive dataset. The responsive frontend delivers an immersive user experience with infinite scrolling, real-time filtering by date ranges and media types, lazy loading for optimal performance, and an interactive modal system for full-resolution media viewing with comprehensive metadata display.\nThis project demonstrates end-to-end software engineering proficiency, from API integration and data pipeline architecture to advanced search algorithm implementation and UI/UX design. The application showcases expertise in information retrieval systems, natural language processing, performance optimization, and creating scalable solutions for large-scale data exploration, making complex scientific archives accessible through intuitive, visually engaging interfaces.",
        start_date: "August 2025",
        end_date: "August 2025",
        image: "/images/nasa_media_explorer.png",
        skills: {
            languages: ["Python", "HTML", "CSS", "JavaScript"],
            frameworks: ["FastAPI", "Bootstrap", "Jinja", "spaCy"],
            tools: ["Git"],
            domains: [],
            soft_skills: [],
        },
        links: [
            {
                label: "GitHub",
                url: "https://github.com/rmluck/NASA-Media-Explorer",
            },
        ],
        featured: true,
    },
    {
        name: "IMDB Review Sentiment Classifier",
        type: "Machine Learning Model",
        brief: "Natural language processing pipeline using Word2Vec embeddings to classify 100,000 [IMDB](https://www.imdb.com) movie reviews with 86% accuracy.",
        description: "Comprehensive sentiment analysis solution that processes 100,000 [IMDB](https://www.imdb.com) movie reviews through a sophisticated natural language processing pipeline. Implemented text processing techniques including HTML tag removal, lemmatization, and stop-word filtering, then leveraged Google's Word2Vec neural embeddings to capture semantic relationships between words. The solution features multiple modeling approaches: traditional bag-of-words with TF-IDF weighting, word vector averaging with semantic clustering, and centroid-based feature extraction. Achieved 86% cross-validated accuracy through ensemble learning with XGBoost and Random Forest, implementing stratified K-fold validation and hyperparameter tuning with early stopping to prevent overfitting. Built for the [\"Bag of Words Meets Bags of Popcorn\" Kaggle competition](https://www.kaggle.com/competitions/word2vec-nlp-tutorial).",
        start_date: "August 2025",
        end_date: "August 2025",
        image: "/images/imdb_review_sentiment_classifier.png",
        skills: {
            languages: ["Python"],
            frameworks: ["NumPy", "Pandas", "Scikit-Learn", "NLTK", "Gensim", "XGBoost"],
            tools: ["Git", "Jupyter", "Kaggle"],
            domains: [],
            soft_skills: [],
        },
        links: [
            {
                label: "GitHub",
                url: "https://github.com/rmluck/Kaggle_IMDB-Review-Sentiment-Classifier",
            },
        ],
        featured: false,
    },
    {
        name: "NFL Mock Draft Simulator",
        type: "Web Application",
        brief: "Full-stack web application that simulates [NFL draft](https://www.nfl.com/draft) scenarios with real-time user team management and automated CPU drafting algorithms.",
        description: "Comprehensive full-stack web application that delivers an immersive [NFL Draft](https://www.nfl.com/draft) simulation experience, combining modern web technologies with sophisticated algorithmic decision-making. Built with a React frontend and FastAPI backend, the platform enables users to control multiple NFL teams simultaneously while an intelligent CPU system manages non-controlled teams using weighted algorithms based on positional needs and player rankings. The application features real-time draft progression, dynamic team roster management, and interactive trade evaluation systems powered by industry-standard draft value charts. The platform demonstrates advanced full-stack development capabilities through its PostgreSQL database architecture, RESTful API design, and responsive user interface that handles complex state management across multiple concurrent draft simulations. Key technical achievements include implementing real-time data synchronization, automated background processing for CPU picks, comprehensive CRUD operations, and seamless deployment across cloud platforms (Netlify, Render, Supabase). The application processes over 250+ player profiles and manages intricate relational data structures while maintaining optimal performance through connection pooling and caching strategies.",
        start_date: "April 2025",
        end_date: "July 2025",
        image: "/images/nfl_mock_draft_simulator.png",
        skills: {
            languages: ["Python", "HTML", "CSS", "JavaScript", "SQL"],
            frameworks: ["React", "React Router", "PostgreSQL", "FastAPI", "SQLAlchemy", "Pydantic"],
            tools: ["Git", "Render", "Netlify", "Supabase"],
            domains: [],
            soft_skills: [],
        },
        links: [
            {
                label: "GitHub",
                url: "https://github.com/rmluck/NFL-Mock-Draft-Simulator",
            },
            {
                label: "Live Site",
                url: "https://nfl-mock-draft-simulator.netlify.app/",
            },
        ],
        featured: true,
    },
    {
        name: "Yelp Review Sentiment Predictor",
        type: "Machine Learning Model",
        brief: "Bayesian machine learning model to predict [Yelp](https://www.yelp.com/) restaurant ratings from sentiment analysis.",
        description: "Machine learning pipeline that leverages Bayesian linear regression to predict [Yelp](https://www.yelp.com/) restaurant star ratings based on customer sentiment analysis and business popularity metrics. The project processed Yelp's massive Open Dataset, filtering down to 664 California restaurants with 50-1,000 reviews to create a robust 30,000+ review dataset for model training and validation. Implemented advanced probabilistic programming techniques using Pyro and PyTorch, incorporating VADER sentiment analysis to extract emotional signals from review text and log-transformed review counts as popularity proxies. The Bayesian approach provided uncertainty quantification through posterior distributions, offering 95% credible intervals for predictions rather than point estimates. The model achieved strong predictive performance with comprehensive evaluation including RMSE metrics, posterior predictive checks, and credible interval analysis.",
        start_date: "May 2025",
        end_date: "June 2025",
        image: "/images/yelp_review_sentiment_predictor.png",
        skills: {
            languages: ["Python"],
            frameworks: ["NumPy", "Pandas", "Matplotlib", "Seaborn", "Scikit-learn", "PyTorch", "NLTK", "Pyro"],
            tools: ["Git", "Jupyter"],
            domains: [],
            soft_skills: [],
        },
        links: [
            {
                label: "GitHub",
                url: "https://github.com/rmluck/Yelp-Review-Sentiment-Predictor",
            },
            {
                label: "Report",
                url: "https://github.com/rmluck/Yelp-Review-Sentiment-Predictor/blob/main/Project%20Report.pdf",
            },
        ],
        featured: true,
    },
    {
        name: "Fabflix",
        type: "Web Application",
        brief: "Cloud-native full-stack web application for film browsing, searching, and purchasing built with large database of films and actors.",
        description: "Cloud-native full-stack e-commerce web application for online movie browsing and purchasing through a sophisticated, scalable architecture. Built from scratch using Java servlets, MySQL, and modern web technologies, the platform manages a massive database of over 15,000 films and 60,000 actors while delivering lightning-fast search functionality powered by full-text indexing, intelligent autocomplete, and caching mechanisms. The application implements enterprise-grade security features including SHA256 password encryption, reCAPTCHA bot protection, and SQL injection prevention through PreparedStatements. Cutting-edge DevOps practices and cloud engineering expertise through containerized deployment pipeline. By leveraging Docker containerization and Kubernetes orchestration across multiple AWS EC2 instances, the application achieves horizontal scalability and high availability. Performance optimization techniques include MySQL connection pooling, master-slave replication, and Apache load balancing resulted in 30% improvement in response times. System architecture incorporates session management, real-time cart functionality, secure payment processing, and an administrative dashboard for content management. Comprehensive performance analysis using JMeter enabled data-driven optimization decisions while the ETL pipeline efficiently processes and imports large-scale film metadata to maintain an up-to-date catalog.",
        start_date: "September 2024",
        end_date: "December 2024",
        image: "/images/fabflix.png",
        skills: {
            languages: ["Java", "HTML", "CSS", "JavaScript", "SQL"],
            frameworks: ["MySQL", "jQuery", "AJAX"],
            tools: ["Git", "Docker", "AWS", "Maven", "Tomcat", "Apache", "reCAPTCHA", "Kubernetes"],
            domains: [],
            soft_skills: [],
        },
        links: [
            {
                label: "GitHub",
                url: "https://github.com/rmluck/Fabflix",
            },
            {
                label: "Demo Videos",
                url: "https://youtube.com/playlist?list=PL8_6c2kgaITUnV0Bt6u-T_5wHl1u7ULs1&si=F-xPowO74VcjJ_x6",
            },
        ],
        featured: true,
    },
    {
        name: "Traffic Signal Control Using Reinforcement Learning",
        type: "Machine Learning Model",
        brief: "Reinforcement learning framework for optimizing traffic signal control in urban environments. Utilizes multi-agent proximal policy optimization (MAPPO) to dynamically adjust signal timings based on real-time traffic data from [CityFlow](https://cityflow.readthedocs.io/en/latest/#) simulations, reducing congestion and improving traffic flow.",
        description: "Multi-agent reinforcement learning (MARL) framework designed and implemented to optimize traffic signal control in urban road networks. Focused on leveraging advanced algorithms like multi-agent proximal policy optimization (MAPPO) to dynamically adjust signal timings based on real-time traffic data, reducing congestion, minimizing vehicle delays, and increasing overall traffic throughput. System treats each intersection as independent agent capable of coordinating actions with neighboring agents while utilizing centralized training and decentralized execution. Implemented dynamic reward functions to encourage smooth traffic flow, integrated [CityFlow](https://cityflow.readthedocs.io/en/latest/#) simulation environments for large-scale testing, and used real-world datasets such as UC Irvine Traffic Flow Forecasting dataset for model evaluation. Implemented features such as detailed state representations and action spaces to manage signal phase configurations. Leveraged Ray's [RLLib library](https://docs.ray.io/en/latest/rllib/index.html) to traing and tune model on training simulations and improve model. Model achieved significant improvements in metrics such as mean velocity, halting duration, and lane occupancy, demonstrating scalability and adaptability in complex traffic environments.",
        // Need to update brief and description using AI later (and update GitHub README)
        start_date: "September 2024",
        end_date: "December 2024",
        image: "/images/traffic_signal_control.png",
        skills: {
            languages: ["Python", "HTML", "CSS", "JavaScript"],
            frameworks: ["RLlib", "NumPy", "Pandas", "Matplotlib", "PyTorch", "Gymnasium"],
            tools: ["Git", "Jupyter"],
            domains: [],
            soft_skills: [],
        },
        links: [
            {
                label: "GitHub",
                url: "https://github.com/rmluck/Traffic-Signal-Control-RL",
            },
            {
                label: "Report",
                url: "https://github.com/rmluck/Traffic-Signal-Control-RL/blob/main/docs/Final%20Project%20Report.pdf",
            },
            {
                label: "Presentation",
                url: "https://github.com/rmluck/Traffic-Signal-Control-RL/blob/main/docs/Final%20Project%20Presentation.pdf",
            },
        ],
        featured: true,
    },
    {
        name: "Atlantis Datathon StrataScratch Exploratory Data Analysis",
        type: "Data Analysis",
        brief: "Exploratory data analysis project focused on the Airbnb market in Dublin. Awarded \"Best Analysis of Airbnb Market in Dublin\" at [UC Irvine Datathon 2024](https://atlantis-datathon-2024.devpost.com/project-gallery).",
        description: "Awarded \"Best Analysis of Airbnb Market in Dublin [Sponsored by [StrataScratch](https://www.stratascratch.com)]\" Award at [UC Irvine Datathon 2024](https://atlantis-datathon-2024.devpost.com/project-gallery). Conducted in-depth exploratory data analysis using StrataScratch datasets. Collaborated with team to visualize insights on market supply and demand, focusing on elevating [Airbnb](https://www.airbnb.com) user experience for guests and hosts. Leveraged tools such as DeepNote, Alteryx Designer, and Python libraries including Pandas, NumPy, Matplotlib, Seaborn, and Scikit-learn to clean, analyze, and visualize data. Developed and tested decision tree classifier machine learning model that achieved 89.35% accuracy.",
        // Need to update brief and description using AI later (and update GitHub README)
        start_date: "April 2024",
        end_date: "April 2024",
        image: "/images/atlantis_datathon.png",
        skills: {
            languages: ["Python"],
            frameworks: ["NumPy", "Pandas", "Matplotlib", "Seaborn", "Scikit-learn"],
            tools: ["Git", "Jupyter", "DeepNote", "Alteryx Designer", "Google Workspace"],
            domains: [],
            soft_skills: [],
        },
        links: [
            {
                label: "GitHub",
                url: "https://github.com/rmluck/Atlantis-Datathon-StrataScratch-Exploratory-Data-Analysis",
            },
            {
                label: "DevPost",
                url: "https://devpost.com/software/lost-in-dublin",
            }
        ],
        featured: true,
    },
    {
        name: "Fashion-MNIST Machine Learning Classifier",
        type: "Machine Learning Model",
        brief: "Web application for classifying [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) images using various machine learning models including Logistic Regression, K-Nearest Neighbors, Feedforward Neural Network, and Convolutional Neural Network. Built with Python and Streamlit.",
        description: "Web application developed using Python and TensorFlow/Keras that classifies images from the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) into one of ten categories (e.g., T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle Boot). The model is trained on a dataset of 70,000 images of various items of clothing. Users can upload grayscale 28x28 images to receive predictions from several employed Scikit-learn machine learning models including Logistic Regression, K-Nearest Neighbors, Feedforward Neural Network, and Convolutional Neural Network. The application also supports evaluation on the test set with detailed visualizations.",
        // Need to update brief and description using AI later (and update GitHub README)
        start_date: "February 2024",
        end_date: "March 2024",
        image: "/images/fashion_mnist_classifier.png",
        skills: {
            languages: ["Python"],
            frameworks: ["NumPy", "Pandas", "Matplotlib", "Seaborn", "Scikit-learn", "TensorFlow", "Keras", "Pillow"],
            tools: ["Git", "Streamlit"],
            domains: [],
            soft_skills: [],
        },
        links: [
            {
                label: "GitHub",
                url: "https://github.com/rmluck/Fashion-MNIST-Machine-Learning-Classifier",
            },
            {
                label: "Live Site",
                url: "https://fashion-mnist-machine-learning-classifier.streamlit.app/",
            }
        ],
        featured: true,
    },
    // {
    //     name: "Google Developer Student Solution Challenge",
    //     type: "",
    //     brief: "",
    //     description: "",
    //     start_date: "January 2024",
    //     end_date: "February 2024",
    //     image: "/images/google_student_developer_challenge.png",
    //     skills: {
    //         languages: [],
    //         frameworks: [],
    //         tools: [],
    //         domains: [],
    //         soft_skills: [],
    //     },
    //     links: [],
    //     featured: false,
    // },
    {
        name: "Netflix Viewing Activity Analysis",
        type: "Data Analysis",
        brief: "Web application for analyzing and visualizing [Netflix](https://www.netflix.com/) viewing history. Provides insights into user viewing patterns based on frequency, duration, and location. Built with Python and Streamlit.",
        description: "Web application designed and developed using Python libraries to process and analyze [Netflix](https://www.netflix.com/) viewing history, deployed with Streamlit. Generates visualizations and insights regarding user viewing patterns based on frequency, duration, and location, providing a comprehensive overview of user behavior. Features include data cleaning, transformation, and interactive visualizations such as bar charts, pie charts, and line graphs to illustrate trends. Users can upload their own viewing history data to explore personalized insights.",
        // Need to update brief and description using AI later (and update GitHub README)
        start_date: "March 2023",
        end_date: "February 2024",
        image: "/images/netflix_viewing_activity_analysis.png",
        skills: {
            languages: ["Python"],
            frameworks: ["NumPy", "Pandas", "Matplotlib", "Seaborn"],
            tools: ["Git", "Streamlit"],
            domains: [],
            soft_skills: [],
        },
        links: [
            {
                label: "GitHub",
                url: "https://github.com/rmluck/Netflix-Viewing-Activity-Analysis",
            },
            {
                label: "Live Site",
                url: "https://netflix-viewing-activity-analysis.streamlit.app/",
            },
        ],
        featured: true,
    },
    {
        name: "Checkers AI",
        type: "Artificial Intelligence Model",
        brief: "AI agent for playing checkers using Monte Carlo Tree Search. Includes command-line interface for human players to compete against the AI. Built with Python.",
        description: "Checkers AI agent developed using Python that employs Monte Carlo Tree Search (MCTS) algorithm to play the game of checkers optimally. The AI evaluates possible moves by simulating numerous random game outcomes, allowing it to make informed decisions based on statistical analysis. The agent reads percepts and acts rationally based on the current state of the game and the opposing player's moves. The implementation includes a command-line interface for human players to compete against the AI, with features such as move validation, game state management, and win/loss detection. The AI is capable of adapting its strategy based on the opponent's skill level, providing a challenging experience for players of varying expertise.",
        // Need to update brief and description using AI later (and update GitHub README)
        start_date: "September 2023",
        end_date: "December 2023",
        image: "/images/checkers_ai.png",
        skills: {
            languages: ["Python", "Java", "C++"],
            frameworks: [],
            tools: ["Git"],
            domains: [],
            soft_skills: [],
        },
        links: [],
        featured: false,
    },
    {
        name: "ICS Search Engine and Web Crawler",
        type: "Search Engine",
        brief: "Customized web search engine and crawler designed for efficient document retrieval and analysis.",
        description: "Customized web search engine and crawler that handles 50,000+ documents under operational contstraints with a query response time under 100ms. Incorporates partial indexing and uses Porter stemmer to improve textual matches. Scraper parses web responses and extracts critical information for detailed report. Improved ranking accuracy by 75% for subset of [UCI ICS web domain pages](https://www.ics.uci.edu/) through TF-IDF weighting and cosine similarity scoring alongside weighted HTML tags. Uses sim-hashing to detect and eliminate near-duplicate pages. Tokenizer built to process text and output word frequencies of pages and shared word frequencies between pages.",
        // Need to update brief and description using AI later (and update GitHub README)
        start_date: "September 2023",
        end_date: "December 2023",
        image: "/images/ics_search_engine.png",
        skills: {
            languages: ["Python", "HTML"],
            frameworks: ["Beautiful Soup", "NLTK"],
            tools: ["Git"],
            domains: [],
            soft_skills: [],
        },
        links: [],
        featured: false,
    },
    {
        name: "The Fall of the World's Own Optimist",
        type: "Game Development",
        brief: "Columns match-three puzzle video game with falling jewels and dynamic gameplay. Built with Python and Pygame.",
        description: "Fully-functioning Columns match-three puzzle video game designed with grid-field of cells and cooled jewels that fall, freeze, match, rotate, shift, and disappear throughout gameplay. Playable version implemented with Python and Pygame.",
        // Need to update brief and description using AI later (and update GitHub README)
        start_date: "February 2022",
        end_date: "February 2022",
        image: "/images/columns.png",
        skills: {
            languages: ["Python"],
            frameworks: ["Pygame"],
            tools: ["Git"],
            domains: [],
            soft_skills: [],
        },
        links: [],
        featured: false,
    },
    {
        name: "Try Not to Breathe",
        type: "Data Analysis",
        brief: "Air quality analysis program that connects to PurpleAir API to monitor air quality based on user-defined location and Air Quality Index threshold.",
        description: "Air quality analysis program that receives location and Air Quality Index threshold as inputs and connects to [PurpleAir API](https://api.purpleair.com) for air quality monitoring sensor data to determine variable number of nearby locations with poorest air quality. [Nominatim API](https://nominatim.org/release-docs/latest/api/Overview/), forward geocoding, and reverse geocoding methods used to calculate nearest locations.",
        // Need to update brief and description using AI later (and update GitHub README)
        start_date: "February 2022",
        end_date: "February 2022",
        image: "/images/try_not_to_breathe.png",
        skills: {
            languages: ["Python"],
            frameworks: [],
            tools: ["Git"],
            domains: [],
            soft_skills: [],
        },
        links: [],
        featured: false,
    },
    {
        name: "Vizzor",
        type: "Engineering Design",
        brief: "Capstone group project focused on designing a solar UV-blocking car visor. Investigated solar radiation issues, analyzed prior solutions, brainstormed concepts, and constructed a physical prototype.",
        description: "Capstone group project involving complete engineering research and design process. Investigated and researched solar ultraviolet radiation issues related to driving. Documented and analyzed prior solution attempts and patents on the market for automobile sun visors that block sun radiation. Brainstormed potential design concepts and generated sketches and 3D models, concluded by printing and constructing physical prototype of car visor. Presented to Civil Engineering and Architecture class.",
        // Need to update brief and description using AI later (and update GitHub README)
        start_date: "August 2020",
        end_date: "May 2021",
        image: "/images/vizzor.png",
        skills: {
            languages: [],
            frameworks: [],
            tools: [],
            domains: [],
            soft_skills: [],
        },
        links: [],
        featured: false,
    }
]